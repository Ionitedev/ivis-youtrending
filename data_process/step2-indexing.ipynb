{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./csv/youtrend_merged1.csv\")\n",
    "# concatenated data among all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tags: string to set\n",
    "\n",
    "tags_col = data['tags'].str.split('|')\n",
    "tags = []\n",
    "for tag_list in tags_col:\n",
    "    tags.append(set(tag_list))\n",
    "data_new = data.drop(['tags'], axis=1)\n",
    "data_new.insert(7, 'tags', tags)\n",
    "\n",
    "# parse dates\n",
    "from dateutil.parser import isoparse\n",
    "# publishing date\n",
    "for idx in range(data_new.shape[0]):\n",
    "    pub_date = data_new['publishedAt'][idx]\n",
    "    data_new.at[idx, 'publishedAt'] = isoparse(pub_date)\n",
    "# trending date\n",
    "for idx in range(data_new.shape[0]):\n",
    "    trend_date = data_new['trending_date'][idx]\n",
    "    data_new.at[idx, 'trending_date'] = isoparse(trend_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lang', 'country', 'video_id', 'title', 'publishedAt', 'channelTitle',\n",
       "       'categoryId', 'tags', 'trending_date', 'view_count', 'likes',\n",
       "       'dislikes', 'comment_count', 'thumbnail_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Sort by trending date\n",
    "\n",
    "data_sorted = data_new.sort_values(by=['video_id'])\n",
    "video_list = list(data_sorted['video_id'].unique())\n",
    "data_re = data_sorted.reset_index()\n",
    "\n",
    "# merge trending dates of one video\n",
    "# video_trend (dict): {video_id: [a list of trending dates]}\n",
    "video_trend = {}\n",
    "index = 0\n",
    "for videoid in video_list:\n",
    "    #print('id:', videoid)\n",
    "    video_trend[videoid] = []\n",
    "    for i in range(index, data_re.shape[0]):\n",
    "        #print(data_re['video_id'][i])\n",
    "        if data_re['video_id'][i]==videoid:\n",
    "            video_trend[videoid].append(data_re['trending_date'][i])\n",
    "        else:\n",
    "            break\n",
    "        index = i+1\n",
    "\n",
    "\n",
    "# video_trend_sorted (dict): {video_id: [a sorted list by trending date]}\n",
    "video_trend_sorted = {}\n",
    "for idx in video_list:\n",
    "    # dates = [isoparse(trend_date) for trend_date in video_trend[idx]]\n",
    "    dates = [trend_date for trend_date in video_trend[idx]]\n",
    "    video_trend_sorted[idx] = sorted(dates)\n",
    "\n",
    "#    \n",
    "index = 0\n",
    "merged_trend_dates = []\n",
    "for videoid in video_list:\n",
    "    #print('id:', videoid)\n",
    "    for i in range(index, data_re.shape[0]):\n",
    "        #print(data_re['video_id'][i])\n",
    "        if data_re['video_id'][i]==videoid:\n",
    "            # data_re.at[i, 'trending_date'] = tuple(video_trend_sorted[videoid])\n",
    "            merged_trend_dates.append(tuple(video_trend_sorted[videoid]))\n",
    "        else:\n",
    "            break\n",
    "        index = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_re.insert(9, 'tuple_trending_dates', merged_trend_dates)\n",
    "data_re2 = data_re.sort_values(by=['trending_date']).reset_index() # sorted by trending date, to get the latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 3, 7, 0, 0, tzinfo=tzutc())"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latest_date = data_re2['trending_date'][data_re2.shape[0]-1] # datetime.datetime(2021, 3, 7, 0, 0, tzinfo=tzutc())\n",
    "# # latest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_re2 = data_re2.drop(['level_0'],axis=1)\n",
    "data_re2 = data_re2.drop(['index'], axis=1)\n",
    "# how to remove 'level_0' and 'index' from the dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data_re2.columns\n",
    "attr = columns.tolist()\n",
    "del attr[2]\n",
    "del attr[-6]\n",
    "alist = list(range(len(attr)))\n",
    "attr = dict(zip(alist, attr))\n",
    "with open('./index/attributes.pickle','wb') as file:\n",
    "    pickle.dump(attr, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase for country names\n",
    "# countries = [cn.lower() for cn in data_re2.country.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_idx = {}\n",
    "for _, row in data_re2.iterrows():\n",
    "    #print(c)\n",
    "    c = row['country']\n",
    "    if not c in country_idx:\n",
    "        country_idx[c] = []\n",
    "    country_idx[c].append(row['video_id'])\n",
    "    #print(row['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-ae3164a4b1e3>:2: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  yt_dict = data_re2.set_index('video_id').T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "# yt_dict = data_re.set_index('video_id').T.to_dict('list')\n",
    "yt_dict = data_re2.set_index('video_id').T.to_dict('list')\n",
    "# view_count, likes, ... correspond to the latest trending date\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# file_to_write = open(\"output.pickle\", \"wb\")\n",
    "# pickle.dump(yt_dict, file_to_write)\n",
    "# file_to_write.close()\n",
    "\n",
    "# yt_dict = {key=video_id: value=(a tuple of attributes)}\n",
    "for key in yt_dict:\n",
    "#     del yt_dict[key][:2] # delete level_0 and index from the pandas dataframe\n",
    "    yt_dict[key] = tuple(yt_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Indices\n",
    "# country_idx:\n",
    "#    keys: 'gb', 'mx', 'fr', 'ru', 'kr', 'us', 'in', 'jp', 'br', 'ca', 'de'\n",
    "# category_idx:\n",
    "#    keys: 23, 10, 24, 2, 26, 22, 17, 20, 27, 25, 28, 19, 15, 1, 29\n",
    "# lang_idx:\n",
    "#    keys: 'en',...,'zh-cn', 'unknown'\n",
    "# trending_idx:\n",
    "#    keys: 1w, 1m, 3m\n",
    "\n",
    "# Category indices\n",
    "category_idx = {}\n",
    "for vid in yt_dict:\n",
    "    ctid = yt_dict[vid][5] # category ID\n",
    "    if not ctid in category_idx:\n",
    "        category_idx[ctid] = []\n",
    "    category_idx[ctid].append(vid)\n",
    "\n",
    "# Language indices\n",
    "lang_idx = {}\n",
    "for vid in yt_dict:\n",
    "    lg = yt_dict[vid][0] # language\n",
    "    if not lg in lang_idx:\n",
    "        lang_idx[lg] = []\n",
    "    lang_idx[lg].append(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yt_dict['UNV6ZfY1Wp0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trending date indices\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# the latest date in the current dataset\n",
    "latest_date = data_re2['trending_date'][data_re2.shape[0]-1] # datetime.datetime(2021, 2, 21, 0, 0, tzinfo=tzutc())\n",
    "\n",
    "trending_1w = []\n",
    "trending_1m = []\n",
    "trending_3m = []\n",
    "for vid in yt_dict:\n",
    "    if latest_date < yt_dict[vid][8]:\n",
    "        raise ValueError('Please update the latest trending date!')\n",
    "    time = latest_date - yt_dict[vid][8]\n",
    "    if time <= timedelta(days=6):\n",
    "        trending_1w.append(vid)\n",
    "    if time <= timedelta(days=30):\n",
    "        trending_1m.append(vid)\n",
    "    if time <= timedelta(days=90):\n",
    "        trending_3m.append(vid)\n",
    "    \n",
    "trending_idx = {'1w': tuple(trending_1w), '1m': tuple(trending_1m), '3m': tuple(trending_3m)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trending_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-59e62354fafc>:2: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  yout = data.set_index('video_id').T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "data = data_re2.drop(['trending_date'],axis=1)\n",
    "yout = data.set_index('video_id').T.to_dict('list')\n",
    "\n",
    "# yt_dict = {key=video_id: value=(a tuple of attributes)}\n",
    "for key in yout:\n",
    "    yout[key] = tuple(yout[key])\n",
    "    \n",
    "import pickle\n",
    "with open(\"./index/youtrend.pickle\",\"wb\") as file_to_write:\n",
    "    pickle.dump(yout, file_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./index/categoryIdx.pickle', 'wb') as file:\n",
    "    pickle.dump(category_idx, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./index/trendingIdx.pickle', 'wb') as file:\n",
    "    pickle.dump(trending_idx, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./index/countryIdx.pickle', 'wb') as file:\n",
    "    pickle.dump(country_idx, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./index/langIdx.pickle', 'wb') as file:\n",
    "    pickle.dump(lang_idx, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
